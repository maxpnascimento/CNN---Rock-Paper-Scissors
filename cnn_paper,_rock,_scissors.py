# -*- coding: utf-8 -*-
"""CNN - Paper, Rock, Scissors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UdIUQ-Ah09kQctnDu7wpglGRa7qjypla

# **CNN - paper, rock, scissors**
___
- Convolution Neural Network for rock/paper/scissors recognition.

author: Max Nascimento

linkedin: linkedin.com/in/max-nascimento-4b19ba109

email: maxpnascimento@gmail.com


---


---
 Reference:
Copyright 2019 The TensorFlow Authors
https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%208%20-%20Lesson%202%20-%20Notebook%20(RockPaperScissors).ipynb#scrollTo=rX8mhOLljYeM

**Libraries**

---
"""

#Libraries
import tensorflow as tf
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
import cv2

"""**Date**

---


"""

#Data and dataAugmentation

#Train data
training_datagen = ImageDataGenerator(                            #Data augmentation
      rescale = 1./255,
	    rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')
train_generator = training_datagen.flow_from_directory(           #Train generator
  "/content/gdrive/MyDrive/CNN - rps/train",
	target_size=(150,150),
	class_mode='categorical',
  batch_size=126
)

#Validation data
validation_datagen = ImageDataGenerator(rescale = 1./255)
validation_generator = validation_datagen.flow_from_directory(    #Validation generator
	"/content/gdrive/MyDrive/CNN - rps/validation",
	target_size=(150,150),
	class_mode='categorical',
  batch_size=64
)

#test data
test_datagen = ImageDataGenerator(rescale = 1./255)
test_generator = test_datagen.flow_from_directory(                 #Test generator
	"/content/gdrive/MyDrive/CNN - rps/test",
	target_size=(150,150),
	class_mode='categorical',
  batch_size=126
)

"""**CNN - Model**"""

#Model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),    #1th convolution - 64 filters - strides 3x3 - Relu activation
    tf.keras.layers.MaxPooling2D(2, 2),                                                 #MaxPooling layer 2x2
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),          #2th convolution - 128 filters - strides 3x3 - Relu activation
    tf.keras.layers.MaxPooling2D(2,2),                              #MaxPooling layer 2x2
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),          #3th convolution - 128 filters - strides 3x3 - Relu activation
    tf.keras.layers.MaxPooling2D(2,2),                              #MaxPooling layer 2x2
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),          #4th convolution - 256 filters - strides 3x3 - Relu activation
    tf.keras.layers.MaxPooling2D(2,2),                              #MaxPooling layer 2x2

    tf.keras.layers.Flatten(),                                      #Flatten
    tf.keras.layers.Dropout(0.5),                                   #Dropout 50%
    
    tf.keras.layers.Dense(512, activation='relu'),                  #Hidden layer - 512 Neurons - Relu activation
    tf.keras.layers.Dense(3, activation='softmax')                  #Output layer - 3 Neurons - softmax activation
])

model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

model.summary()

with tf.device('/device:GPU:0'):
  history = model.fit(train_generator, epochs=30, steps_per_epoch=10, validation_data = validation_generator, verbose = 1, validation_steps=1)

"""**Test**"""

#Test model (Accuracy)
model.evaluate(test_generator)